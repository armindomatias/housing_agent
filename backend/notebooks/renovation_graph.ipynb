{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renovation Graph Node Testing\n",
    "\n",
    "This notebook allows you to test individual nodes of the renovation estimation pipeline.\n",
    "\n",
    "## Modes\n",
    "\n",
    "- **Fixture mode** (`MODE = \"fixture\"`): Uses offline fixture data, no API calls\n",
    "- **Live mode** (`MODE = \"live\"`): Makes real API calls to Apify/OpenAI\n",
    "\n",
    "## Pipeline Steps\n",
    "\n",
    "1. **Scrape**: Fetch property data from Idealista via Apify\n",
    "2. **Classify**: Classify each image to identify room types\n",
    "3. **Group**: Group images by room (pure logic, always runs live)\n",
    "4. **Estimate**: Analyze each room and estimate renovation costs\n",
    "5. **Summarize**: Generate final report with totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path so we can import app modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "backend_dir = Path.cwd().parent\n",
    "if str(backend_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(backend_dir))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(backend_dir / \".env\")\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "from pprint import pprint\n",
    "from app.config import Settings\n",
    "from app.graphs.main_graph import (\n",
    "    scrape_node,\n",
    "    classify_node,\n",
    "    group_node,\n",
    "    estimate_node,\n",
    "    summarize_node,\n",
    "    build_renovation_graph,\n",
    ")\n",
    "from app.graphs.state import create_initial_state\n",
    "from fixtures import get_state_after, SAMPLE_URL\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mode Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose mode: \"fixture\" or \"live\"\n",
    "MODE = \"fixture\"  # Change to \"live\" for real API calls\n",
    "\n",
    "# Initialize settings\n",
    "settings = Settings()\n",
    "\n",
    "# For live mode, optionally override the sample URL\n",
    "IDEALISTA_URL = SAMPLE_URL  # Change this for live mode\n",
    "\n",
    "print(f\"Mode: {MODE}\")\n",
    "print(f\"URL: {IDEALISTA_URL}\")\n",
    "if MODE == \"live\":\n",
    "    print(f\"OpenAI Model (estimation): {settings.openai_vision_model}\")\n",
    "    print(f\"OpenAI Model (classification): {settings.openai_classification_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available fixture stages\n",
    "stages = [\"initial\", \"scrape\", \"classify\", \"group\", \"estimate\", \"summarize\"]\n",
    "print(\"Available fixture stages:\")\n",
    "for stage in stages:\n",
    "    state = get_state_after(stage)\n",
    "    print(f\"  - {stage}: current_step='{state.get('current_step', 'N/A')}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(state, keys=None):\n",
    "    \"\"\"Pretty-print specific keys from state.\"\"\"\n",
    "    if keys is None:\n",
    "        keys = [\"current_step\", \"error\"]\n",
    "    \n",
    "    subset = {k: state.get(k) for k in keys if k in state}\n",
    "    pprint(subset)\n",
    "\n",
    "\n",
    "def show_events(state):\n",
    "    \"\"\"Show stream events from state.\"\"\"\n",
    "    events = state.get(\"stream_events\", [])\n",
    "    print(f\"\\nStream Events ({len(events)}):\")\n",
    "    for i, event in enumerate(events, 1):\n",
    "        msg = event.message if hasattr(event, 'message') else event.get('message', '')\n",
    "        event_type = event.type if hasattr(event, 'type') else event.get('type', '')\n",
    "        print(f\"  {i}. [{event_type}] {msg}\")\n",
    "\n",
    "\n",
    "def show_property_data(state):\n",
    "    \"\"\"Show scraped property data.\"\"\"\n",
    "    prop = state.get(\"property_data\")\n",
    "    if prop:\n",
    "        print(f\"\\nProperty Data:\")\n",
    "        print(f\"  Title: {prop.title if hasattr(prop, 'title') else prop.get('title', 'N/A')}\")\n",
    "        print(f\"  Price: {prop.price if hasattr(prop, 'price') else prop.get('price', 0):,.0f}€\")\n",
    "        print(f\"  Area: {prop.area_m2 if hasattr(prop, 'area_m2') else prop.get('area_m2', 0)} m²\")\n",
    "        num_images = len(prop.image_urls) if hasattr(prop, 'image_urls') else len(prop.get('image_urls', []))\n",
    "        print(f\"  Images: {num_images}\")\n",
    "\n",
    "\n",
    "def show_classifications(state):\n",
    "    \"\"\"Show classification results.\"\"\"\n",
    "    classifications = state.get(\"classifications\", [])\n",
    "    print(f\"\\nClassifications ({len(classifications)}):\")\n",
    "    for i, c in enumerate(classifications, 1):\n",
    "        room_type = c.room_type.value if hasattr(c, 'room_type') else c.get('room_type', 'N/A')\n",
    "        room_num = c.room_number if hasattr(c, 'room_number') else c.get('room_number', 0)\n",
    "        conf = c.confidence if hasattr(c, 'confidence') else c.get('confidence', 0)\n",
    "        print(f\"  {i}. {room_type} #{room_num} (confidence: {conf:.2f})\")\n",
    "\n",
    "\n",
    "def show_grouped_images(state):\n",
    "    \"\"\"Show grouped images by room.\"\"\"\n",
    "    grouped = state.get(\"grouped_images\", {})\n",
    "    print(f\"\\nGrouped Images ({len(grouped)} rooms):\")\n",
    "    for room_key, images in grouped.items():\n",
    "        print(f\"  {room_key}: {len(images)} image(s)\")\n",
    "\n",
    "\n",
    "def show_room_analyses(state):\n",
    "    \"\"\"Show room analysis results.\"\"\"\n",
    "    analyses = state.get(\"room_analyses\", [])\n",
    "    print(f\"\\nRoom Analyses ({len(analyses)}):\")\n",
    "    for analysis in analyses:\n",
    "        label = analysis.room_label if hasattr(analysis, 'room_label') else analysis.get('room_label', 'N/A')\n",
    "        condition = analysis.condition.value if hasattr(analysis, 'condition') else analysis.get('condition', 'N/A')\n",
    "        cost_min = analysis.cost_min if hasattr(analysis, 'cost_min') else analysis.get('cost_min', 0)\n",
    "        cost_max = analysis.cost_max if hasattr(analysis, 'cost_max') else analysis.get('cost_max', 0)\n",
    "        num_items = len(analysis.renovation_items) if hasattr(analysis, 'renovation_items') else len(analysis.get('renovation_items', []))\n",
    "        print(f\"  {label}: {condition} | {cost_min:,.0f}€ - {cost_max:,.0f}€ | {num_items} items\")\n",
    "\n",
    "\n",
    "def show_estimate(state):\n",
    "    \"\"\"Show final estimate.\"\"\"\n",
    "    estimate = state.get(\"estimate\")\n",
    "    if estimate:\n",
    "        total_min = estimate.total_cost_min if hasattr(estimate, 'total_cost_min') else estimate.get('total_cost_min', 0)\n",
    "        total_max = estimate.total_cost_max if hasattr(estimate, 'total_cost_max') else estimate.get('total_cost_max', 0)\n",
    "        summary = estimate.summary if hasattr(estimate, 'summary') else estimate.get('summary', '')\n",
    "        print(f\"\\nFinal Estimate:\")\n",
    "        print(f\"  Total: {total_min:,.0f}€ - {total_max:,.0f}€\")\n",
    "        print(f\"  Summary: {summary[:150]}...\" if len(summary) > 150 else f\"  Summary: {summary}\")\n",
    "\n",
    "print(\"✅ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Node 1: Scrape\n",
    "\n",
    "Fetch property data from Idealista via Apify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"fixture\":\n",
    "    # Load fixture state\n",
    "    state_after_scrape = get_state_after(\"scrape\")\n",
    "    print(\"✅ Loaded fixture state after scrape\")\n",
    "else:\n",
    "    # Run live scrape\n",
    "    initial_state = create_initial_state(IDEALISTA_URL, user_id=\"notebook_test\")\n",
    "    state_after_scrape = await scrape_node(initial_state, settings=settings)\n",
    "    print(\"✅ Scrape completed\")\n",
    "\n",
    "show_state(state_after_scrape, [\"current_step\", \"error\"])\n",
    "show_property_data(state_after_scrape)\n",
    "show_events(state_after_scrape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Node 2: Classify\n",
    "\n",
    "Classify each image to identify room types using GPT-4o-mini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"fixture\":\n",
    "    # Load fixture state\n",
    "    state_after_classify = get_state_after(\"classify\")\n",
    "    print(\"✅ Loaded fixture state after classify\")\n",
    "else:\n",
    "    # Run live classify\n",
    "    state_after_classify = await classify_node(state_after_scrape, settings=settings)\n",
    "    print(\"✅ Classify completed\")\n",
    "\n",
    "show_state(state_after_classify, [\"current_step\", \"error\"])\n",
    "show_classifications(state_after_classify)\n",
    "show_events(state_after_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Node 3: Group\n",
    "\n",
    "Group images by room (pure logic, no API calls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always run live (pure logic, no API calls)\n",
    "if MODE == \"fixture\":\n",
    "    state_after_group = get_state_after(\"group\")\n",
    "    print(\"✅ Loaded fixture state after group\")\n",
    "else:\n",
    "    state_after_group = await group_node(state_after_classify, settings=settings)\n",
    "    print(\"✅ Group completed\")\n",
    "\n",
    "show_state(state_after_group, [\"current_step\", \"error\"])\n",
    "show_grouped_images(state_after_group)\n",
    "show_events(state_after_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Node 4: Estimate\n",
    "\n",
    "Analyze each room and estimate renovation costs using GPT-4o Vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"fixture\":\n",
    "    # Load fixture state\n",
    "    state_after_estimate = get_state_after(\"estimate\")\n",
    "    print(\"✅ Loaded fixture state after estimate\")\n",
    "else:\n",
    "    # Run live estimate\n",
    "    state_after_estimate = await estimate_node(state_after_group, settings=settings)\n",
    "    print(\"✅ Estimate completed\")\n",
    "\n",
    "show_state(state_after_estimate, [\"current_step\", \"error\"])\n",
    "show_room_analyses(state_after_estimate)\n",
    "show_events(state_after_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Node 5: Summarize\n",
    "\n",
    "Generate final report with totals and summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"fixture\":\n",
    "    # Load fixture state\n",
    "    state_after_summarize = get_state_after(\"summarize\")\n",
    "    print(\"✅ Loaded fixture state after summarize\")\n",
    "else:\n",
    "    # Run live summarize\n",
    "    state_after_summarize = await summarize_node(state_after_estimate, settings=settings)\n",
    "    print(\"✅ Summarize completed\")\n",
    "\n",
    "show_state(state_after_summarize, [\"current_step\", \"error\"])\n",
    "show_estimate(state_after_summarize)\n",
    "show_events(state_after_summarize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Full Graph (Live Mode Only)\n",
    "\n",
    "Run the complete graph end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"live\":\n",
    "    print(\"Running full graph end-to-end...\")\n",
    "    graph = build_renovation_graph(settings)\n",
    "    initial_state = create_initial_state(IDEALISTA_URL, user_id=\"notebook_test\")\n",
    "    \n",
    "    final_state = await graph.ainvoke(initial_state)\n",
    "    \n",
    "    print(\"\\n✅ Full graph completed\")\n",
    "    show_state(final_state, [\"current_step\", \"error\"])\n",
    "    show_estimate(final_state)\n",
    "else:\n",
    "    print(\"⚠️  Full graph execution only available in live mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Graph Visualization\n",
    "\n",
    "Display the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph and show structure\n",
    "graph = build_renovation_graph(settings)\n",
    "\n",
    "try:\n",
    "    # Try to display as mermaid if available\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # Fallback to ASCII\n",
    "    print(\"Graph structure:\")\n",
    "    print(\"\"\"\\nSCRAPE → CLASSIFY → GROUP → ESTIMATE → SUMMARIZE → END\\n\"\"\")\n",
    "    print(\"Each node receives state and settings as parameters.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
